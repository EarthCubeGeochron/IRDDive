---
title: "Secondary Data Papers"
author: "Jeremiah Marsicek and Simon Goring"
date: "4/20/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Locating Key-terms in Secondary Data Papers

What do we do with key-terms that are in secondary data papers?  This is a small Rmd to help us look for key-terms in secondary data papers and then apply the regex across all of them (or some of them).

```{r load_packages, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
devtools::install_github('EarthCubeGeochron/geodiveR')

library(geodiveR)

library(jsonlite)
library(readr)
library(dplyr)
library(stringr)
library(leaflet)
library(purrr)
library(DT)
library(assertthat)

sourcing <- list.files('R', full.names = TRUE) %>% 
  map(source, echo = FALSE, print = FALSE, verbose = FALSE)

publications <- fromJSON(txt = 'input/bibjson', flatten = TRUE)
full_nlp <- readr::read_tsv('input/sentences_nlp352', 
                       trim_ws = TRUE,
                       col_names = c('_gddid', 'sentence', 'wordIndex', 
                                     'word', 'partofspeech', 'specialclass', 
                                     'wordsAgain', 'wordtype', 'wordmodified'))

nlp_clean <- clean_corpus(x = full_nlp, pubs = publications) #uses the clean_corpus.R function

nlp <- nlp_clean$nlp

```

Let's first identify papers where IRD is mentioned after the discussion in the paper, pull those papers, then write regex to pull information, like maybe the reference to IRD. 

```{r}
ird_disc <- function(x, pubs) {

disc <- stringr::str_detect(x$word, "Discussion")
ird_word <- stringr::str_detect(x$word, "[,\\{/]IRD[,-/]")

sec_sent <- data.frame(index = which(disc|ird_word),
                      gddid = x$`_gddid`[disc|ird_word],
                      sent = x$sentence[disc|ird_word],
                      disc = disc[disc|ird_word],
                      word = ird_word[disc|ird_word],
                      drop_gd = NA,
                      stringsAsFactors = FALSE)

# Go through each paper in the table:
for(i in unique(sec_sent$gddid)) {
  
  if(any(sec_sent$gddid == i & sec_sent$disc == TRUE)){
  
    disc_sent <- min(sec_sent$sent[sec_sent$gddid == i & sec_sent$disc == TRUE])
    
    nogood <- all(sec_sent$sent[sec_sent$gddid == i & sec_sent$word == TRUE] >= disc_sent)
    
    if(nogood) {
      sec_sent$drop_gd[sec_sent$gddid == i] <- TRUE
    } else {
      sec_sent$drop_gd[sec_sent$gddid == i] <- FALSE
    }
  } else {
    sec_sent$drop_gd[sec_sent$gddid == i] <- FALSE
  }
}

discussion_drops <- x$`_gddid` %in% unique(sec_sent$gddid[sec_sent$drop_gd])


good_gddid_disc <- which(ird_word & !discussion_drops)

gddid_all_disc <- unique(x$`_gddid`[good_gddid_disc])

return(list(nlp = x[x$`_gddid` %in% gddid_all_disc,],
            gddlist = list(drop = pubs$`_gddid`[!pubs$`_gddid` %in% gddid_all_disc],
                           keep = pubs$`_gddid`[pubs$`_gddid` %in% gddid_all_disc])))
}

ird_after_disc<-ird_disc(x = nlp_clean$nlp, pubs = publications)

```

We've established some basic regex to try to pull key-terms from secondary data papers.

```{r broad_coords, echo=TRUE, message=FALSE, eval = FALSE}

sec_data <- "(([,-]\\d{1,3}[^a-zA-Z0-9]{1,4}\\d+?.{1,7}){1,4})([NESWnesw]?)," #write a regular expression to search for IRD references in discussion?

  #"^((?=.*?\\bword\\b)(?=.*?\\bword\\b)(?=.*?\\bword\\b).*$)," ##try something like this

sec_match <- stringr::str_detect(nlp$word, sec_data)

browse(sec_match, corpus = ird_after_disc$nlp, pubs = publications)

```